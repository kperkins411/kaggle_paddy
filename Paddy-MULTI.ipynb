{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db68348-6675-4711-81e1-fa1b04fc694d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Paddy Kaggle Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4eb0ea0-2a7d-4b6b-946c-75bc2a83e970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_setup():\n",
    "    # How to download competition data to temp folder(data) \n",
    "    # unzip it there, then symlink it like its a subdir\n",
    "    # NOTE: make sure kaggle.json is in /root/.kaggle/\n",
    "\n",
    "    #remove original symlink from this directory\n",
    "    !rm ./data\n",
    "    \n",
    "    #remove old setup files\n",
    "    !rm setup.sh\n",
    "\n",
    "    #create temp holder\n",
    "    !mkdir /root/data\n",
    "\n",
    "    #symlink it\n",
    "    !ln -s /root/data ./data\n",
    "\n",
    "    #download competition data to temp data folder\n",
    "    !cd ./data;kaggle competitions download -c paddy-disease-classification\n",
    "\n",
    "    #unzip it, -q is silent\n",
    "    !cd ./data;unzip -q paddy-disease-classification.zip\n",
    "\n",
    "    #setup dotfiles\n",
    "    !wget \"https://raw.githubusercontent.com/CNUClasses/dotfiles/master/setup.sh\";chmod 766 setup.sh;source ./setup.sh  \n",
    "    \n",
    "import os\n",
    "if(not os.path.exists('./data/train_images')):\n",
    "   !chmod 600 /root/.kaggle/kaggle.json\n",
    "   do_setup()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "984bf6e1-34f9-4408-9447-220207210d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install needed libraries\n",
    "try: from path import Path\n",
    "except ModuleNotFoundError:\n",
    "    !pip install path --quiet\n",
    "    from path import Path\n",
    "try: import timm\n",
    "except ModuleNotFoundError:\n",
    "    !pip install timm --quiet\n",
    "    import timm\n",
    "try: import optuna\n",
    "except ModuleNotFoundError:\n",
    "    !pip install optuna --quiet\n",
    "    import optuna    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "528a1f00-c4f2-41bf-9fc4-b48ebdcbf0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "sklearn.__version__\n",
    "import paddy_funcs_classes as pfc\n",
    "\n",
    "# autoreload extension\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1414b30-7a45-4364-91df-9d852abae75d",
   "metadata": {},
   "source": [
    "## CFG file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52fb0c93-7f68-421b-af92-c8145be53fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://www.kaggle.com/code/hinepo/transfer-learning-with-timm-models-and-pytorch\n",
    "class CFG:\n",
    "    train_path='./data/train_images'   #get train and validation Datasets from here\n",
    "    test_path='./data/test_images'     #get test set from here\n",
    "    csv_path='./data/train.csv'\n",
    "    \n",
    "    ### split train and validation sets\n",
    "    split_fraction = 0.2\n",
    "\n",
    "    ##dataloader\n",
    "    drop_last=False\n",
    "    \n",
    "    ### model\n",
    "    model_name = 'resnet26d'#'convnext_small_in22k' # ## 'resnet50' # 'resnet34', 'resnet200d', 'efficientnet_b1_pruned', 'efficientnetv2_m', efficientnet_b7 ...  \n",
    "\n",
    "    #get a subset of data to work on(start with True until all experiments done\n",
    "    #and want to train on entire dataset\n",
    "    subsample_data=False\n",
    "    BATCH_SIZE= 8 if subsample_data else 32\n",
    "    N_EPOCHS = 4 if subsample_data else 50\n",
    "    # print_freq = 2 \n",
    "\n",
    "    momentum=0.9\n",
    "    \n",
    "    ### set only one to True\n",
    "    save_best_loss = False\n",
    "    save_best_accuracy = True\n",
    "\n",
    "    ### optimizer\n",
    "    # optimizer = 'adam'\n",
    "    # optimizer = 'adamw'\n",
    "    optimizer = 'rmsprop'  \n",
    "    # LEARNING_RATE=0.00001\n",
    "    LEARNING_RATE_MIN=0.004\n",
    "    LEARNING_RATE_MAX=0.01\n",
    "\n",
    "    random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1a9e6c-82ae-4708-95ae-730eab72aa06",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "835142b2-22ad-4d9f-8ea9-96c9aafd745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(CFG.csv_path)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53680f1-019d-4dca-8ac9-82078650828d",
   "metadata": {},
   "source": [
    "### EXPERIMENT ON SUBSET OF DATA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f05165b7-bb97-491a-9c44-f9799d1ab05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.subsample_data:\n",
    "    #stratify dataframe by multiple columns (see Paddy-Multi.ipynb)\n",
    "    # df, _ = train_test_split(df, test_size=0.5, random_state=0, stratify=df[['label', 'variety']])\n",
    "\n",
    "#     #get a small dataset to train on\n",
    "    df=df.iloc[:500,:]\n",
    "\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0bea5cc-f9eb-4e00-aede-5121f6412d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len train=10407, length test=3469\n"
     ]
    }
   ],
   "source": [
    "# #get a list of files\n",
    "trn_val_files=pfc.get_fls(CFG.train_path)  \n",
    "tst_files=pfc.get_fls(CFG.test_path) \n",
    "print(f'Len train={len(trn_val_files)}, length test={len(tst_files)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8300b8-13cf-48e6-a279-1c9d9f31ab11",
   "metadata": {},
   "source": [
    "### Stratified Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ca212dc-7f0f-4359-82e4-43b573d58a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10407"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stratify dataframe by multiple columns (see Paddy-Multi.ipynb)\n",
    "train, val = train_test_split(df, test_size=CFG.split_fraction, random_state=0, stratify=df[['label', 'variety']])\n",
    "len(train) + len(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a4fbcd-0c43-4393-b888-09213eb35289",
   "metadata": {},
   "source": [
    "### Get list of transforms that the original model used (mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ed43233-cafd-43e0-9aaa-6200d5658266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': (3, 224, 224),\n",
       " 'interpolation': 'bicubic',\n",
       " 'mean': (0.485, 0.456, 0.406),\n",
       " 'std': (0.229, 0.224, 0.225),\n",
       " 'crop_pct': 0.875}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg=timm.data.resolve_data_config({}, model=CFG.model_name, verbose=True)\n",
    "cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d771e97a-1dff-4213-8fac-449c43162910",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66b710fd-c4cd-49b6-97b8-9f3c1ea4e4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number train images=8325, number validation=2082, and number test images=3469\n"
     ]
    }
   ],
   "source": [
    "#forward and reverse map labels and varieties\n",
    "mpr=pfc.mapper(df)\n",
    "\n",
    "#get transforms\n",
    "train_transforms, val_transforms=pfc.get_transforms(cfg)\n",
    "\n",
    "trn_dataset = pfc.MultiTaskDatasetTrain(CFG.train_path,df=train,mpr=mpr,transforms=train_transforms) #use train df\n",
    "val_dataset = pfc.MultiTaskDatasetTrain(CFG.train_path,df=val,mpr=mpr,transforms=val_transforms)   #use val df\n",
    "test_dataset= pfc.MultiTaskDatasetTest(CFG.test_path, transforms=val_transforms)            #test set\n",
    "\n",
    "print(f'Number train images={len(trn_dataset)}, number validation={len(val_dataset)}, and number test images={len(test_dataset)}')\n",
    "\n",
    "if(not CFG.subsample_data):\n",
    "    assert(len(trn_dataset)+len(val_dataset)==len(trn_val_files))\n",
    "    assert(len(test_dataset)==len(tst_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cfea65-514e-43e5-a715-143f7c3eb15b",
   "metadata": {},
   "source": [
    "### Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "724ebefa-f7c6-4889-8b21-70962f9f57ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "trn_dl=DataLoader(trn_dataset, batch_size=CFG.BATCH_SIZE, shuffle=True, num_workers=2,drop_last=CFG.drop_last) #drop last to avoid crash\n",
    "# trn_dl=DataLoader(val_dataset, batch_size=CFG.BATCH_SIZE, shuffle=True, num_workers=2,drop_last=CFG.drop_last) #drop last to avoid crash\n",
    "\n",
    "val_dl=DataLoader(val_dataset, batch_size=CFG.BATCH_SIZE, shuffle=True, num_workers=2,drop_last=CFG.drop_last)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ff3ff7-5db6-431c-9ed2-c619444d5490",
   "metadata": {},
   "source": [
    "#### Sizes from DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db6200bd-72d3-4180-91f7-9ce232d5d883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 3, 224, 224])\n",
      "Labels batch shape: torch.Size([32])\n",
      "Varieties batch shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "imgs,lbls,varieties = next(iter(val_dl))\n",
    "print(f\"Feature batch shape: {imgs.size()}\")\n",
    "print(f\"Labels batch shape: {lbls.size()}\")\n",
    "print(f\"Varieties batch shape: {varieties.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d609aa-4c74-4310-8d4a-6becd5f994e2",
   "metadata": {},
   "source": [
    "#### Show the images <mark> is this correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24acc842-b5c8-4f07-9dac-51ee8cdf8bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_some_images():\n",
    "    #look at original image and new one\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    img1,lbl,variety = val_dataset[0]\n",
    "\n",
    "    # original image (PIL)\n",
    "    Image.open(val_dataset.files[0]).show()\n",
    "\n",
    "    #see returned as a PIL image\n",
    "    import torchvision.transforms as T\n",
    "    transform = T.ToPILImage()\n",
    "    transform(img1).show()\n",
    "\n",
    "    #show as raw tensor\n",
    "    def show(img):\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation='nearest')\n",
    "    show(img1)\n",
    "\n",
    "    mpr=pfc.mapper(df)   \n",
    "    print(f\"Label: {mpr.i_to_label[lbl]}\")\n",
    "    print(f\"Variety: {mpr.i_to_variety[variety]}\")\n",
    "    \n",
    "# show_some_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d21d1e-3444-4e00-8f5e-adc41731df4c",
   "metadata": {},
   "source": [
    "### Try and find a good learning rate, Optuna and Fastai LR finder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbb4b2d-4597-496c-8e6f-c9747f006a17",
   "metadata": {},
   "source": [
    "#### Load Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1c2cc8e-2cbc-4ee0-80c8-a98b243909bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 µs, sys: 3 µs, total: 13 µs\n",
      "Wall time: 17.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import optuna\n",
    "\n",
    "def objective(trial,trn_dl=trn_dl,val_dl=val_dl):\n",
    "    \n",
    "    #these are the parameters I want to optimize\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1)\n",
    "    \n",
    "    #get a model\n",
    "    lrn=get_model(CFG.model_name,min_lr=lr,max_lr=10*lr, num_epochs=1,trn_dl=trn_dl)\n",
    "\n",
    "    #train the model\n",
    "    lrn._trn_epoch(trn_dl)\n",
    "    \n",
    "    #see how good it is\n",
    "    acc_labl,_ = pfc.get_accuracy(lrn.m,val_dl, verbose=False)\n",
    "    \n",
    "    #get the cross validation score\n",
    "    return acc_labl\n",
    "\n",
    "#object that will optimize the objective\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# #start optimizing, go for 50 rounds\n",
    "# study.optimize(objective, n_trials=3)\n",
    "\n",
    "# trial = study.best_trial\n",
    "\n",
    "# print('best accuracy: {}'.format(trial.value))\n",
    "# print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1563a91-5888-41da-ac1c-f8bffb7dc64a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95aa7cfa-f3db-4f3a-9c0d-a3be56f234fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 768 ms, sys: 83 ms, total: 851 ms\n",
      "Wall time: 464 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_epochs=10\n",
    "lrn=pfc.get_Learner(model_name=CFG.model_name,min_lr=CFG.LEARNING_RATE_MIN,max_lr=CFG.LEARNING_RATE_MAX, num_epochs=num_epochs,trn_dl=trn_dl,momentum=CFG.momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69e467c0-5fec-4c00-821a-f0643800d21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:err_rate_labels=0.55,   label_loss=1.62,  err_rate_varieties=0.28 varieties_loss=0.89\n",
      "valid:err_rate_labels=0.41,   label_loss=1.23,  err_rate_varieties=0.21 varieties_loss=0.67\n",
      "Epoch 0found and saving better model\n",
      "\n",
      "train:err_rate_labels=0.37,   label_loss=1.13,  err_rate_varieties=0.20 varieties_loss=0.63\n",
      "valid:err_rate_labels=0.48,   label_loss=1.53,  err_rate_varieties=0.49 varieties_loss=1.39\n",
      "train:err_rate_labels=0.32,   label_loss=0.96,  err_rate_varieties=0.17 varieties_loss=0.52\n",
      "valid:err_rate_labels=0.26,   label_loss=0.78,  err_rate_varieties=0.13 varieties_loss=0.39\n",
      "Epoch 2found and saving better model\n",
      "\n",
      "train:err_rate_labels=0.25,   label_loss=0.75,  err_rate_varieties=0.13 varieties_loss=0.39\n",
      "valid:err_rate_labels=0.21,   label_loss=0.65,  err_rate_varieties=0.12 varieties_loss=0.36\n",
      "Epoch 3found and saving better model\n",
      "\n",
      "train:err_rate_labels=0.20,   label_loss=0.60,  err_rate_varieties=0.09 varieties_loss=0.29\n",
      "valid:err_rate_labels=0.19,   label_loss=0.54,  err_rate_varieties=0.05 varieties_loss=0.18\n",
      "Epoch 4found and saving better model\n",
      "\n",
      "train:err_rate_labels=0.17,   label_loss=0.53,  err_rate_varieties=0.08 varieties_loss=0.24\n",
      "valid:err_rate_labels=0.12,   label_loss=0.37,  err_rate_varieties=0.05 varieties_loss=0.16\n",
      "Epoch 5found and saving better model\n",
      "\n",
      "train:err_rate_labels=0.14,   label_loss=0.42,  err_rate_varieties=0.06 varieties_loss=0.18\n",
      "valid:err_rate_labels=0.10,   label_loss=0.30,  err_rate_varieties=0.03 varieties_loss=0.08\n",
      "Epoch 6found and saving better model\n",
      "\n",
      "train:err_rate_labels=0.11,   label_loss=0.34,  err_rate_varieties=0.04 varieties_loss=0.13\n",
      "valid:err_rate_labels=0.07,   label_loss=0.24,  err_rate_varieties=0.02 varieties_loss=0.06\n",
      "Epoch 7found and saving better model\n",
      "\n",
      "train:err_rate_labels=0.08,   label_loss=0.25,  err_rate_varieties=0.03 varieties_loss=0.09\n",
      "valid:err_rate_labels=0.06,   label_loss=0.18,  err_rate_varieties=0.01 varieties_loss=0.04\n",
      "Epoch 8found and saving better model\n",
      "\n",
      "train:err_rate_labels=0.07,   label_loss=0.23,  err_rate_varieties=0.03 varieties_loss=0.07\n",
      "valid:err_rate_labels=0.06,   label_loss=0.16,  err_rate_varieties=0.01 varieties_loss=0.04\n",
      "Epoch 9found and saving better model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "lrn.learn(trn_dl,val_dl,num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47d9bb3-8988-4590-95ad-1a14de0dc797",
   "metadata": {},
   "source": [
    "### Lets plot the cyclic learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f792b1b3-d286-4ec5-a24e-3387eec2848c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6dd23ec640>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(lrn.lrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaebae79-fc9f-4d8b-adaa-0cf6099b49d6",
   "metadata": {},
   "source": [
    "## Predict on the val set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72d42993-eece-4d83-bfd1-6e13e607b606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: Label prediction=82.05%,  Variety prediction=90.67\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(82.05492424242425, 90.67234848484848)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfc.get_accuracy(lrn.m,val_dl)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552803ec-3330-446f-8fb3-0831f8e83a68",
   "metadata": {},
   "source": [
    "## Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b192da-3e8c-42fd-86b5-6dfa8ee02d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate sorted list of files\n",
    "test_dataset=MultiTaskDatasetTest(CFG.test_path, transforms=val_transforms) \n",
    "test_dataset.files.sort()\n",
    "\n",
    "#generate a non_shuffle dataloader\n",
    "tst_dl=DataLoader(test_dataset, batch_size=CFG.BATCH_SIZE, shuffle=False, num_workers=1,drop_last=False)\n",
    "\n",
    "#where is the model\n",
    "device = next(m1.parameters()).device.type\n",
    "\n",
    "#get model predictions\n",
    "labels=[]\n",
    "for imgs in tst_dl:\n",
    "    imgs = imgs.to(device)\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    pred_lbls,_ = lrn.m(imgs)\n",
    "    \n",
    "    #get the max index\n",
    "    pred_lbls=torch.argmax(pred_lbls,dim=1).tolist()\n",
    "    labels=labels+pred_lbls   \n",
    "\n",
    "#convert indexes to labels\n",
    "new_labels=[mpr.i_to_label[i] for i in labels]\n",
    "# get a list of files\n",
    "files=[fle.split('/')[-1] for fle in test_dataset.files]   \n",
    "\n",
    "with open('./submission.csv','w') as fle:\n",
    "    fle.write('image_id,label')\n",
    "    for i in range(len(files)):\n",
    "        fle.write('\\n'+files[i]+','+new_labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66059f1-ec8c-4b4c-ae34-504a3b705013",
   "metadata": {},
   "source": [
    "## Zip And Upload to Kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0c5c7a-ae25-427e-af9c-968597e16506",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip ./submission.zip ./submission.csv\n",
    "!kaggle competitions submit -c paddy-disease-classification -f submission.zip -m \"Message\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d946d6ba-9b22-480d-9c33-3ae3805140be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d854e1e-e3d4-42c8-a011-8d3c90172544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#where is this model located?\n",
    "# tmodel1=timm.create_model(model_name, pretrained=True, num_classes=13,global_pool='catavgmax')  #going to replace the 13\n",
    "# next(tmodel1.parameters()).device.type\n",
    "\n",
    "#     def _one_epoch(self,dl,training):\n",
    "#         running_loss_labels = 0.0\n",
    "#         running_loss_varieties = 0.0\n",
    "#         running_err_rate_labels =0.0\n",
    "#         running_err_rate_varieties =0.0\n",
    "#         is_trn=self.m.training\n",
    "        \n",
    "#         # for i, data in (enumerate(tqdm(dl), 0)):\n",
    "#         print()\n",
    "#         for i, data in (enumerate(dl)):\n",
    "\n",
    "#             # get the inputs, labels is tuple(label, variety)\n",
    "#             imgs,lbls,varietys = data[0].to(self.device),data[1].to(self.device),data[2].to(self.device)\n",
    "           \n",
    "#             if training:\n",
    "#                 # zero the parameter gradients\n",
    "#                 self.optimizer.zero_grad()\n",
    " \n",
    "#             # forward + backward + optimize\n",
    "#             pred_lbls,pred_varieties = self.m(imgs)\n",
    "             \n",
    "#             loss_labels , loss_varieties = self.criterion(pred_lbls,pred_varieties, lbls,varietys)\n",
    "            \n",
    "#             if training:\n",
    "#                 #see https://stackoverflow.com/questions/46774641/what-does-the-parameter-retain-graph-mean-in-the-variables-backward-method\n",
    "#                 loss_labels.backward(retain_graph=True)\n",
    "#                 loss_varieties.backward()\n",
    "\n",
    "#             running_loss_labels+=loss_labels.item()\n",
    "#             running_loss_varieties+=loss_varieties.item()\n",
    "#             running_err_rate_labels+=error_rate(pred_lbls,lbls)\n",
    "#             running_err_rate_varieties+=error_rate(pred_varieties,varietys)\n",
    " \n",
    "#             #adjust weights\n",
    "#             self.optimizer.step()\n",
    "\n",
    "#             if (i%CFG.print_freq==0):\n",
    "#                 state='train' if is_trn else 'valid' \n",
    "#                 print(f'{state}:err_rate_labels={(running_err_rate_labels/(i)):.2f},   label_loss={(running_loss_labels):.2f},   err_rate_varieties={(running_err_rate_varieties/(i)):.2f}   varieties_loss={(running_loss_varieties):.2f},    ', end='\\r', flush=True)\n",
    "#                 running_loss_labels = 0.0\n",
    "#                 running_loss_varieties = 0.0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0338cf58-1441-466e-a44c-9e646c681446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1.train()\n",
    "# m1.eval()\n",
    "# print(f'{m1.training}, {m1.m.training}, {m1.m.fc.training}')\n",
    "\n",
    "#check shapes\n",
    "# (next(iter(trn_dl))[-2:])\n",
    "\n",
    "# m1.eval()\n",
    "# m1(trn_dataset[0][0].unsqueeze(0))\n",
    "\n",
    " #calls forward\n",
    "# m1(next(iter(trn_dl))[0]) \n",
    "# m1(val_dataset[0].unsqueeze(0))\n",
    "\n",
    "# m1(torch.randn(1,3,224,224))\n",
    "\n",
    "\n",
    "\n",
    "# criterion=DiseaseAndTypeClassifierLoss()\n",
    "# optimizer = optim.SGD(m1.parameters(), lr=0.001, momentum=0.9)\n",
    "# num_epochs=3\n",
    "# numb_batches_between_prints=1\n",
    "\n",
    "        \n",
    "        \n",
    "# for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "#     running_loss_labels = 0.0\n",
    "#     running_loss_varieties = 0.0\n",
    "#     num_batches=len(trn_dl)/trn_dl.batch_size\n",
    "#     m1.train()\n",
    "#     for i, data in (enumerate(tqdm(trn_dl), 0)):\n",
    "\n",
    "#         # get the inputs, labels is tuple(label, variety)\n",
    "#         imgs,lbls,varietys = data[0].to(device),data[1].to(device),data[2].to(device)\n",
    "\n",
    "#         # zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # forward + backward + optimize\n",
    "#         pred_lbls,pred_varieties = m1(imgs)\n",
    "        \n",
    "#         #loss\n",
    "#         # loss = criterion(pred_lbls,pred_varieties, lbls,varietys)\n",
    "#         # loss.backward()\n",
    "#         loss_labels , loss_varieties = criterion(pred_lbls,pred_varieties, lbls,varietys)\n",
    "#         loss_labels.backward()\n",
    "#         loss_varieties.backward()\n",
    "        \n",
    "#         running_loss_labels+=loss_labels.item()\n",
    "#         running_loss_varieties+=loss_varieties.item()\n",
    "        \n",
    "#         #adjust weights\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         if i%numb_batches_between_prints==0:\n",
    "#             if(\n",
    "#             print(f'label_loss={running_loss_labels/(numb_batches_between_prints*batch_size):.2f}, \\\n",
    "#                   varieties_loss={running_loss_varieties/(numb_batches_between_prints*batch_size):.2f}', end='\\r', flush=True)\n",
    "#             running_loss_labels = 0.0\n",
    "#             running_loss_varieties = 0.0\n",
    "    \n",
    "#     # m1.eval()\n",
    "#     # num_batches=len(val_dl)/batch_size\n",
    "#     # for i, data in (enumerate(tqdm(val_dl), 0)): \n",
    "\n",
    "        \n",
    "        \n",
    " \n",
    "\n",
    "# # print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92c4b8e-a05e-4202-9017-d029a3674465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=np.nan\n",
    "# a\n",
    "\n",
    "# import math\n",
    "# assert (math.isnan(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9419f6-8409-4012-a338-231679818127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1=timm.create_model('resnet26d', pretrained=True, num_classes=10,global_pool='catavgmax')  #going to replace the 13\n",
    "# m2=timm.create_model(CFG.model_name, pretrained=True, num_classes=10,global_pool='catavgmax')  #going to replace the 13\n",
    "\n",
    "# def get_fc(m):\n",
    "#     #when iterator is exhausted, item will hold last layer\n",
    "#     for item in m.children():\n",
    "#         pass\n",
    "#     print(type(item))\n",
    "#     if(isinstance(item,torch.nn.modules.linear.Linear)):\n",
    "#         print('Its linear')\n",
    "#     else:\n",
    "#         item= get_fc(item)   \n",
    "#     return item\n",
    "\n",
    "# fcl=get_fc(m1)\n",
    "# m2.head.fc=nn.Sequential(\n",
    "#             nn.Linear(in_features=m1.get_classifier().in_features,out_features=512, bias=False),\n",
    "#             nn.ReLU())\n",
    "\n",
    "\n",
    "\n",
    "# m11=DiseaseAndTypeClassifier(m1)\n",
    "# m22=DiseaseAndTypeClassifier(m2)\n",
    "\n",
    "# #convnext has no m1.fc, get its head this way\n",
    "# tmodel.head.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cd36d6-d7fa-473a-90e9-d7ae7ee0cbc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
