{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dad9a8b1-dde8-481b-8336-af6836abf069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DiseaseAndTypeClassifier(nn.Module):\n",
    "    def __init__(self,tmodel):\n",
    "        '''\n",
    "        tmodel: pretrained model\n",
    "        ex:\n",
    "        model_name='resnet26d'\n",
    "        tmodel=timm.create_model(model_name, pretrained=True)\n",
    "        m1=DiseaseAndTypeClassifier(tmodel)\n",
    "        \n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.m = tmodel\n",
    "        \n",
    "        #do this if you want to replace head of self.m\n",
    "        #get model head\n",
    "        # self.\n",
    "#         h=list(self.m.named_modules())[-1]\n",
    "#         print(h[0])\n",
    "#         h[1]=nn.Linear(in_features=self.m.get_classifier().in_features,out_features=99, bias=False)\n",
    "#         print(list(self.m.named_modules())[-1])\n",
    "        \n",
    "        self.s=nn.Sequential(\n",
    "            #do this if you want to add a head that matches the output size of self.m\n",
    "            nn.Linear(in_features=self.m.get_classifier().out_features,out_features=512, bias=False),                \n",
    "            nn.ReLU())\n",
    "        self.l1=nn.Linear(in_features=512, out_features=10, bias=False)  #rice type\n",
    "        self.l2=nn.Linear(in_features=512, out_features=10, bias=False)  #disease\n",
    "        \n",
    "    def forward(self,x): \n",
    "        x=self.m(x)\n",
    "        x=self.s(x)     \n",
    "        label=self.l1(x)  #disease type\n",
    "        variety=self.l2(x)  #variety\n",
    "        return label,variety\n",
    "\n",
    "    \n",
    "class smallm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #linear network expects linear input\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.l1=nn.Sequential(\n",
    "            nn.Linear(in_features=256,out_features=512, bias=False),\n",
    "            nn.ReLU())\n",
    "        self.l2=nn.Sequential(\n",
    "            nn.Linear(in_features=512,out_features=512, bias=False),\n",
    "            nn.ReLU())\n",
    "        # self.head=nn.Sequential(\n",
    "        #     nn.Linear(in_features=512,out_features=10, bias=False),\n",
    "        #     nn.ReLU())        \n",
    "        self.head=nn.Linear(in_features=512,out_features=10, bias=False)\n",
    "    def forward(self,x):\n",
    "        x=self.flatten(x)\n",
    "        x=self.l1(x)\n",
    "        x=self.l2(x)\n",
    "        x=self.l2(x)\n",
    "        out0=self.head(x)\n",
    "        out1=self.head(x)\n",
    "        return out0,out1\n",
    "    \n",
    "    def get_classifier(self):\n",
    "        #you can see what type it is and input and output params\n",
    "        return self.head\n",
    "        \n",
    "\n",
    "# m_in=nn.Sequential(\n",
    "#             nn.Linear(in_features=self.m.get_classifier().in_features,out_features=512, bias=False),\n",
    "#             nn.ReLU())\n",
    "sm=smallm()\n",
    "m1=DiseaseAndTypeClassifier(sm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9611d1ec-f1c6-47f2-b7f9-3cb83e36ed24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smallm(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (l1): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=512, bias=False)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (l2): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (head): Linear(in_features=512, out_features=10, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1aa15fb9-5a41-462e-8ee6-d8724dcb428a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smallm(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (l1): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=512, bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (l2): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (head): Linear(in_features=512, out_features=10, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# list(smallm().modules())\n",
    "print(smallm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4cdaa091-84e8-46e3-904c-0f4f6441e618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=512, bias=False)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (1): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#want to remove the head?  Works with forward as well (head, last sequential is removed from it)\n",
    "#but it then becomes a nn.Sequential object, you lose all the stuff that made it a smallm model\n",
    "s=smallm()\n",
    "s=nn.Sequential(*list(s.children())[:-1])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03c258dd-c915-420c-893f-c7fdd4e92cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Parameter containing:\n",
      "tensor([[ 0.0503, -0.0471, -0.0006,  ..., -0.0281, -0.0501, -0.0057],\n",
      "        [-0.0165,  0.0101, -0.0625,  ...,  0.0080,  0.0299,  0.0152],\n",
      "        [ 0.0180, -0.0514,  0.0101,  ..., -0.0426, -0.0405,  0.0009],\n",
      "        ...,\n",
      "        [ 0.0106, -0.0184,  0.0349,  ..., -0.0269, -0.0406,  0.0212],\n",
      "        [ 0.0330, -0.0154,  0.0414,  ..., -0.0400, -0.0016,  0.0080],\n",
      "        [-0.0512,  0.0574,  0.0174,  ..., -0.0257,  0.0127,  0.0517]],\n",
      "       requires_grad=True)\n",
      "True\n",
      "Parameter containing:\n",
      "tensor([[-0.0264, -0.0250, -0.0241,  ..., -0.0013,  0.0173, -0.0113],\n",
      "        [-0.0194, -0.0440,  0.0262,  ..., -0.0091, -0.0402,  0.0085],\n",
      "        [ 0.0290,  0.0323,  0.0216,  ..., -0.0187,  0.0417, -0.0074],\n",
      "        ...,\n",
      "        [-0.0296,  0.0103, -0.0433,  ...,  0.0175,  0.0436,  0.0197],\n",
      "        [-0.0322,  0.0368,  0.0085,  ...,  0.0334,  0.0063,  0.0175],\n",
      "        [ 0.0284,  0.0135, -0.0128,  ..., -0.0358,  0.0158, -0.0366]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for child in s.children():\n",
    "    for param in child.parameters():\n",
    "        print(param.requires_grad)\n",
    "        print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0843ec3c-cef7-4c0d-8443-3df1a64c6212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.weight True\n",
      "2.0.weight True\n"
     ]
    }
   ],
   "source": [
    "for name, param in s.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3adb139a-27ea-42e6-a656-d928b6589f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in s.children():\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "258a5318-35aa-4f37-bd1d-1ee2dc1671d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "tmodel=timm.create_model('resnet26d', pretrained=True, num_classes=512,global_pool='catavgmax') \n",
    "print(tmodel.get_classifier().in_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "93c946ed-3466-41d5-9ad8-d87dd84bd940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip the head and convert to a Sequential\n",
    "nm=nn.Sequential(*list(tmodel.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7a9c9d31-0114-4a8e-9d04-828e72a5db46",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'get_classifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [84]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_classifier\u001b[49m()\u001b[38;5;241m.\u001b[39min_features\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1207\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'get_classifier'"
     ]
    }
   ],
   "source": [
    "nm.get_classifier().in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51a74247-ad9d-4edd-8f31-cfdc1bdb932b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#get all the parameters for the l1 layer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[43mm1\u001b[49m\u001b[38;5;241m.\u001b[39ml2\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mlen\u001b[39m(p[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      5\u001b[0m p[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m9\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm1' is not defined"
     ]
    }
   ],
   "source": [
    "#get all the parameters for the l1 layer\n",
    "p=list(m1.l2.parameters())\n",
    "\n",
    "len(p[0])\n",
    "p[0][9]\n",
    "\n",
    "type(p)\n",
    "p[0].requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b965aef-c262-41ef-9946-3dba3580baec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.1117,  0.0419, -0.0875,  ..., -0.0762,  0.0960,  0.0056],\n",
       "         [ 0.0098,  0.0295, -0.0530,  ..., -0.0715,  0.1092, -0.0794],\n",
       "         [ 0.0860,  0.1053,  0.0559,  ..., -0.0113,  0.0444, -0.1116],\n",
       "         ...,\n",
       "         [-0.0368,  0.0990,  0.0697,  ...,  0.0029,  0.0611, -0.0217],\n",
       "         [ 0.0424, -0.0100,  0.0332,  ..., -0.0335, -0.0245, -0.1022],\n",
       "         [-0.0782, -0.0470,  0.0407,  ...,  0.0659, -0.0937,  0.0376]],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2=list(m1.m.head.parameters())\n",
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b90be383-f3f1-4550-969f-6c5849598320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND1\n",
      "smallm(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (l1): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=512, bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (l2): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (head): Sequential(\n",
      "    (0): Linear(in_features=76, out_features=99, bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n",
      "FOUND1\n",
      "Sequential(\n",
      "  (0): Linear(in_features=99, out_features=512, bias=False)\n",
      "  (1): ReLU()\n",
      ")\n",
      "FOUND1\n",
      "Linear(in_features=512, out_features=10, bias=False)\n",
      "FOUND1\n",
      "Linear(in_features=512, out_features=10, bias=False)\n"
     ]
    }
   ],
   "source": [
    "for child in m1.children():\n",
    "    print('FOUND1')\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47dece89-cd65-44b6-9b01-2780d59056cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.m.fc=nn.Linear(in_features=512,out_features=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "493fede6-897e-4fbf-bd87-bbc2beb5f0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiseaseAndTypeClassifier(\n",
      "  (m): smallm(\n",
      "    (l1): Sequential(\n",
      "      (0): Linear(in_features=10, out_features=512, bias=False)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (l12): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=256, bias=False)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (rl): ReLU()\n",
      "  (l1): Linear(in_features=512, out_features=10, bias=False)\n",
      "  (l2): Linear(in_features=512, out_features=10, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006cbb4a-c1f7-4124-ba5a-62816e76b43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = torch.rand(3,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b160e8e8-73ac-48a1-ac58-7702419a632b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smallm(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (l1): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=512, bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (l2): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc): Linear(in_features=512, out_features=256, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "sm=smallm()\n",
    "print(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37c71bb8-e3d8-48b3-b2cb-c7b8afb5bd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3884,  1.0749],\n",
      "        [-0.2458, -0.2331]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.3884,  1.0749],\n",
      "        [-0.2458, -0.2331]])\n",
      "tensor([[ 0.4868, -0.2339],\n",
      "        [ 0.1149, -0.1691]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Use .detach() to get x2 without grad and the whole computing graph stays same.\n",
    "lin0 = nn.Linear(2, 2)\n",
    "lin1 = nn.Linear(2, 2)\n",
    "x1 = torch.randn(2, 2)\n",
    "x2 = lin0(x1)\n",
    "x3 = lin1(x2)\n",
    "output = x2.detach()\n",
    "print(x2)\n",
    "print(output)\n",
    "print(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7239804-fc02-4d77-97e4-82e17c9c7574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None tensor([[0.1426, 0.8418],\n",
      "        [0.1426, 0.8418]])\n"
     ]
    }
   ],
   "source": [
    "# You can use output as part of other graphs.\n",
    "x4 = lin1(output)\n",
    "x4.sum().backward()\n",
    "print(lin0.weight.grad, lin1.weight.grad)\n",
    "# The backward of this new graph doesn't affect the initial graph. That's why lin0.weight.grad is None.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af236d98-4732-4347-a502-358317960b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1457,  0.8600],\n",
      "        [-0.1082, -0.6386]]) None tensor([[ 0.1352, -1.5110],\n",
      "        [ 0.1352, -1.5110]])\n"
     ]
    }
   ],
   "source": [
    "# The output variable of a frozen model keeps the gradient tracking and you are able to backpropogate through it. \n",
    "# However, it doesn't affect the gradient. This is a good proprety that we want.\n",
    "lin0 = nn.Linear(2, 2)\n",
    "lin1 = nn.Linear(2, 2)\n",
    "lin2 = nn.Linear(2, 2)\n",
    "x3 = lin0(x2)\n",
    "for param in lin1.parameters():\n",
    "    param.requires_grad = False\n",
    "x4 = lin1(x3)\n",
    "x5 = lin2(x4)\n",
    "x5.sum().backward()\n",
    "print(lin0.weight.grad, lin1.weight.grad, lin2.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef59286e-2f0b-4d11-9c30-38ebcfc290e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(2*3, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.h1=nn.Linear(8, 3)\n",
    "        self.h2=nn.Linear(8, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear_relu_stack(x)\n",
    "        x = self.linear_relu_stack(x)\n",
    "        o1=self.h1(x)\n",
    "        o2=self.h2(x)\n",
    "        return o1,o2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30b1ecd5-a16f-4574-86cd-d6da5af42726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1545,  0.3736, -0.3435,  0.0399,  0.1408, -0.0583],\n",
      "        [ 0.3021, -0.3993,  0.2122, -0.1926, -0.2593,  0.0273],\n",
      "        [ 0.3910,  0.2362, -0.2592, -0.3741,  0.1457, -0.0029],\n",
      "        [ 0.0457,  0.3631,  0.1568, -0.2177,  0.1282,  0.1381],\n",
      "        [-0.3662, -0.0367, -0.1060,  0.1888,  0.0237,  0.2178],\n",
      "        [-0.0620, -0.1117,  0.3076,  0.2571,  0.0704,  0.2905],\n",
      "        [-0.1825,  0.3836, -0.2615,  0.3017, -0.2123, -0.1978],\n",
      "        [-0.2592,  0.0386, -0.2730, -0.2817, -0.2072,  0.1349]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1503, -0.0760,  0.1067,  0.1963,  0.2854,  0.2776, -0.0633, -0.0066],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-2.6617e-01,  1.0101e-01,  7.0075e-02, -1.2686e-01,  1.7857e-01,\n",
      "          9.1110e-02, -3.1292e-01, -1.8995e-01],\n",
      "        [ 1.4165e-01,  2.6779e-03, -2.5487e-02,  3.0827e-01,  1.5819e-01,\n",
      "         -2.4409e-01,  8.3514e-02, -2.6360e-01],\n",
      "        [ 2.2916e-01,  3.7602e-02, -2.7017e-01,  1.7751e-01,  1.6834e-01,\n",
      "         -4.5488e-03,  3.0111e-01, -2.6221e-02],\n",
      "        [-6.9666e-02, -6.3779e-02,  3.4798e-02,  1.6440e-02, -1.1263e-01,\n",
      "          3.4679e-01, -2.8922e-01,  3.4923e-01],\n",
      "        [ 8.4041e-05,  1.2544e-01, -1.6374e-01, -1.0831e-01, -1.3246e-01,\n",
      "         -2.2867e-02, -1.7574e-01, -7.4348e-02],\n",
      "        [ 2.8689e-01,  2.6956e-01,  2.1638e-01,  2.1544e-01, -8.2204e-02,\n",
      "         -3.9645e-02,  3.2013e-01,  1.5205e-01],\n",
      "        [ 2.5249e-01,  1.7537e-01,  8.0697e-02,  1.3650e-01, -2.7746e-01,\n",
      "         -8.7909e-02, -2.3126e-01, -1.0300e-01],\n",
      "        [ 4.8026e-02,  7.4335e-02,  1.9176e-01, -1.6587e-01, -5.3941e-02,\n",
      "         -2.1462e-01,  2.6916e-01,  2.9586e-01]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2817,  0.3031,  0.2389,  0.1238, -0.2155, -0.0255, -0.1303, -0.2512],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0727,  0.1112, -0.2022,  0.2416, -0.2412, -0.1196,  0.1223,  0.1462],\n",
      "        [-0.1862, -0.2467, -0.2096,  0.1540, -0.2641,  0.1010, -0.1655,  0.2326],\n",
      "        [-0.0280,  0.2092,  0.0846,  0.2844, -0.1992, -0.0243, -0.1571, -0.2931]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1053, -0.0217,  0.3246], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0682, -0.0430, -0.1060,  0.1286, -0.1453, -0.3360, -0.0165,  0.2786],\n",
      "        [-0.2310,  0.2101,  0.2293, -0.0786,  0.0678, -0.2894, -0.3287, -0.2132],\n",
      "        [-0.0506,  0.2347, -0.3390, -0.2252, -0.3034, -0.2125, -0.2265,  0.0541],\n",
      "        [-0.3274, -0.1425, -0.0159, -0.1192,  0.1651,  0.1282,  0.1159, -0.1002],\n",
      "        [ 0.1626, -0.0251,  0.3108,  0.2219,  0.2231,  0.2974, -0.0300, -0.1565]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3335,  0.2898, -0.0882,  0.2165,  0.2703], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "s1=NeuralNetwork()\n",
    "for child in s1.children():\n",
    "    for param in child.parameters():\n",
    "        print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1073942d-4c2f-4b3d-bdad-b670446199b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=8, out_features=3, bias=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b403a66a-898e-4d94-b503-998a824a8170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changes h1\n",
    "s1.h1=nn.Linear(30, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "371c4864-6e0a-4773-9f67-4bee207e246c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=6, out_features=8, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=8, out_features=8, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (h1): Linear(in_features=30, out_features=20, bias=True)\n",
       "  (h2): Linear(in_features=8, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3251d7cf-732f-4be4-a14c-5e58e7321196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([8, 6]) | Values : tensor([[ 0.1545,  0.3736, -0.3435,  0.0399,  0.1408, -0.0583],\n",
      "        [ 0.3021, -0.3993,  0.2122, -0.1926, -0.2593,  0.0273]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([8]) | Values : tensor([-0.1503, -0.0760], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([8, 8]) | Values : tensor([[-0.2662,  0.1010,  0.0701, -0.1269,  0.1786,  0.0911, -0.3129, -0.1900],\n",
      "        [ 0.1416,  0.0027, -0.0255,  0.3083,  0.1582, -0.2441,  0.0835, -0.2636]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([8]) | Values : tensor([-0.2817,  0.3031], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: h1.weight | Size: torch.Size([20, 30]) | Values : tensor([[-0.1648, -0.1640, -0.0968,  0.0409, -0.0515, -0.0127,  0.0749,  0.0308,\n",
      "          0.0458,  0.0718, -0.1257, -0.0869, -0.1731,  0.1237, -0.1215, -0.1805,\n",
      "          0.1117, -0.0183,  0.0063, -0.0267, -0.0675,  0.0119, -0.1084, -0.1337,\n",
      "         -0.0102,  0.0526, -0.0286,  0.0284,  0.0595, -0.0295],\n",
      "        [ 0.0378,  0.0988,  0.1491, -0.0309,  0.0449,  0.1172,  0.1293, -0.1242,\n",
      "         -0.0136,  0.1240, -0.0029,  0.0182, -0.0831, -0.1555, -0.0013,  0.0220,\n",
      "         -0.1266, -0.0113, -0.1165, -0.1167, -0.0242,  0.0283,  0.0183, -0.0234,\n",
      "          0.0336,  0.1343,  0.0511, -0.0837, -0.0669,  0.1351]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: h1.bias | Size: torch.Size([20]) | Values : tensor([-0.0454,  0.0714], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: h2.weight | Size: torch.Size([5, 8]) | Values : tensor([[-0.0682, -0.0430, -0.1060,  0.1286, -0.1453, -0.3360, -0.0165,  0.2786],\n",
      "        [-0.2310,  0.2101,  0.2293, -0.0786,  0.0678, -0.2894, -0.3287, -0.2132]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: h2.bias | Size: torch.Size([5]) | Values : tensor([0.3335, 0.2898], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in s1.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a92a6d5-5de1-4579-85d7-1c54fdc33848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('linear_relu_stack.0.weight', Parameter containing:\n",
      "tensor([[ 0.1545,  0.3736, -0.3435,  0.0399,  0.1408, -0.0583],\n",
      "        [ 0.3021, -0.3993,  0.2122, -0.1926, -0.2593,  0.0273],\n",
      "        [ 0.3910,  0.2362, -0.2592, -0.3741,  0.1457, -0.0029],\n",
      "        [ 0.0457,  0.3631,  0.1568, -0.2177,  0.1282,  0.1381],\n",
      "        [-0.3662, -0.0367, -0.1060,  0.1888,  0.0237,  0.2178],\n",
      "        [-0.0620, -0.1117,  0.3076,  0.2571,  0.0704,  0.2905],\n",
      "        [-0.1825,  0.3836, -0.2615,  0.3017, -0.2123, -0.1978],\n",
      "        [-0.2592,  0.0386, -0.2730, -0.2817, -0.2072,  0.1349]],\n",
      "       requires_grad=True)), ('linear_relu_stack.0.bias', Parameter containing:\n",
      "tensor([-0.1503, -0.0760,  0.1067,  0.1963,  0.2854,  0.2776, -0.0633, -0.0066],\n",
      "       requires_grad=True)), ('linear_relu_stack.2.weight', Parameter containing:\n",
      "tensor([[-2.6617e-01,  1.0101e-01,  7.0075e-02, -1.2686e-01,  1.7857e-01,\n",
      "          9.1110e-02, -3.1292e-01, -1.8995e-01],\n",
      "        [ 1.4165e-01,  2.6779e-03, -2.5487e-02,  3.0827e-01,  1.5819e-01,\n",
      "         -2.4409e-01,  8.3514e-02, -2.6360e-01],\n",
      "        [ 2.2916e-01,  3.7602e-02, -2.7017e-01,  1.7751e-01,  1.6834e-01,\n",
      "         -4.5488e-03,  3.0111e-01, -2.6221e-02],\n",
      "        [-6.9666e-02, -6.3779e-02,  3.4798e-02,  1.6440e-02, -1.1263e-01,\n",
      "          3.4679e-01, -2.8922e-01,  3.4923e-01],\n",
      "        [ 8.4041e-05,  1.2544e-01, -1.6374e-01, -1.0831e-01, -1.3246e-01,\n",
      "         -2.2867e-02, -1.7574e-01, -7.4348e-02],\n",
      "        [ 2.8689e-01,  2.6956e-01,  2.1638e-01,  2.1544e-01, -8.2204e-02,\n",
      "         -3.9645e-02,  3.2013e-01,  1.5205e-01],\n",
      "        [ 2.5249e-01,  1.7537e-01,  8.0697e-02,  1.3650e-01, -2.7746e-01,\n",
      "         -8.7909e-02, -2.3126e-01, -1.0300e-01],\n",
      "        [ 4.8026e-02,  7.4335e-02,  1.9176e-01, -1.6587e-01, -5.3941e-02,\n",
      "         -2.1462e-01,  2.6916e-01,  2.9586e-01]], requires_grad=True)), ('linear_relu_stack.2.bias', Parameter containing:\n",
      "tensor([-0.2817,  0.3031,  0.2389,  0.1238, -0.2155, -0.0255, -0.1303, -0.2512],\n",
      "       requires_grad=True)), ('h1.weight', Parameter containing:\n",
      "tensor([[-0.1648, -0.1640, -0.0968,  0.0409, -0.0515, -0.0127,  0.0749,  0.0308,\n",
      "          0.0458,  0.0718, -0.1257, -0.0869, -0.1731,  0.1237, -0.1215, -0.1805,\n",
      "          0.1117, -0.0183,  0.0063, -0.0267, -0.0675,  0.0119, -0.1084, -0.1337,\n",
      "         -0.0102,  0.0526, -0.0286,  0.0284,  0.0595, -0.0295],\n",
      "        [ 0.0378,  0.0988,  0.1491, -0.0309,  0.0449,  0.1172,  0.1293, -0.1242,\n",
      "         -0.0136,  0.1240, -0.0029,  0.0182, -0.0831, -0.1555, -0.0013,  0.0220,\n",
      "         -0.1266, -0.0113, -0.1165, -0.1167, -0.0242,  0.0283,  0.0183, -0.0234,\n",
      "          0.0336,  0.1343,  0.0511, -0.0837, -0.0669,  0.1351],\n",
      "        [-0.0687, -0.1716, -0.0851,  0.1215, -0.1403, -0.0590, -0.0634,  0.1550,\n",
      "          0.0241, -0.0967, -0.1213,  0.0286,  0.0836, -0.0397, -0.1458,  0.0329,\n",
      "         -0.1775, -0.0470, -0.1029,  0.1546,  0.0689, -0.0649, -0.0988,  0.1318,\n",
      "          0.0068, -0.1187,  0.0505, -0.1051, -0.0073,  0.1178],\n",
      "        [-0.1604, -0.1431,  0.1105, -0.0517, -0.0166,  0.0299, -0.1544,  0.0962,\n",
      "         -0.0082, -0.1501, -0.0600,  0.0763,  0.0889, -0.0314, -0.1597,  0.1535,\n",
      "         -0.0798,  0.0306,  0.1243,  0.0401,  0.0792, -0.1207,  0.1449, -0.0735,\n",
      "         -0.1145, -0.1617, -0.0195, -0.0830,  0.0494,  0.1697],\n",
      "        [ 0.1616, -0.1527,  0.0862, -0.1548,  0.0960, -0.0620,  0.0949,  0.0797,\n",
      "         -0.1724,  0.0270,  0.1543, -0.0185, -0.0820,  0.1406, -0.0094, -0.1553,\n",
      "          0.1091,  0.1481,  0.0362,  0.1521, -0.1582, -0.1284, -0.0008, -0.0069,\n",
      "          0.1136, -0.0665, -0.0415,  0.0942,  0.0710,  0.0128],\n",
      "        [ 0.1029, -0.1741, -0.1293,  0.1150, -0.1201, -0.1175,  0.0760, -0.1361,\n",
      "          0.1075, -0.1755,  0.0605, -0.0406,  0.0266,  0.0190,  0.0783, -0.0340,\n",
      "         -0.0432, -0.1207,  0.0648, -0.0873, -0.0965, -0.0200,  0.0634,  0.0218,\n",
      "          0.1546,  0.1453, -0.0278, -0.0007,  0.1138, -0.1671],\n",
      "        [-0.1707, -0.1311, -0.0009, -0.0074, -0.1670, -0.0744, -0.0403,  0.1735,\n",
      "         -0.1694, -0.0546,  0.0084,  0.0798, -0.1168, -0.1165, -0.1533, -0.0792,\n",
      "         -0.1500,  0.1721, -0.1078, -0.1470,  0.0682, -0.1294,  0.0294,  0.0234,\n",
      "          0.1700,  0.1819,  0.0359, -0.1176,  0.0394, -0.1209],\n",
      "        [-0.1521, -0.1817, -0.1578, -0.0471, -0.1594,  0.1227,  0.0563,  0.1315,\n",
      "         -0.1200,  0.1043, -0.0385,  0.0217, -0.0139,  0.0605, -0.1326,  0.0536,\n",
      "          0.0212, -0.0292,  0.0850,  0.1491,  0.0166,  0.1282, -0.1515,  0.1480,\n",
      "         -0.1307,  0.1144,  0.1818, -0.1601, -0.0542,  0.0811],\n",
      "        [ 0.1793,  0.0400,  0.1764, -0.0284,  0.1409, -0.0003, -0.0527, -0.0994,\n",
      "          0.0584,  0.1117, -0.0012, -0.1440,  0.1072, -0.1485, -0.0840,  0.1316,\n",
      "         -0.1144, -0.0547, -0.0529, -0.0973,  0.1643, -0.1666, -0.0292,  0.0859,\n",
      "          0.0057,  0.1308,  0.0101,  0.0438, -0.0418,  0.1733],\n",
      "        [-0.0280,  0.1673, -0.1122, -0.1578,  0.1315,  0.1288,  0.1512, -0.1381,\n",
      "         -0.0615, -0.1260, -0.0367,  0.0553,  0.0627,  0.0895, -0.1648,  0.0940,\n",
      "          0.0931,  0.0349, -0.0239,  0.0322,  0.0711, -0.0664,  0.1679, -0.1016,\n",
      "          0.0525,  0.1602,  0.1772, -0.0603,  0.1667, -0.0027],\n",
      "        [ 0.0264,  0.0154, -0.0187, -0.0482,  0.1300, -0.1301,  0.1790,  0.1347,\n",
      "          0.0971, -0.0464,  0.1234, -0.1728,  0.0736, -0.1448, -0.0303,  0.0007,\n",
      "          0.0240, -0.0212, -0.0082,  0.1501, -0.1157,  0.0155, -0.0382,  0.1727,\n",
      "         -0.1800,  0.0169,  0.0012, -0.1482, -0.0071,  0.0486],\n",
      "        [ 0.0358,  0.0208,  0.1323, -0.1153,  0.1667,  0.0545,  0.0100,  0.0299,\n",
      "          0.0674,  0.1442, -0.0544,  0.0893,  0.0972,  0.0370,  0.0753, -0.0376,\n",
      "         -0.0620,  0.0725, -0.0370,  0.0809, -0.1446, -0.1159,  0.1511, -0.1369,\n",
      "          0.1050, -0.0068, -0.1666, -0.1568, -0.1433,  0.1455],\n",
      "        [-0.0207, -0.1478, -0.0810, -0.0122,  0.0773, -0.1608, -0.1335, -0.1440,\n",
      "         -0.0304, -0.0459,  0.1054, -0.1303, -0.1555, -0.0853, -0.1721, -0.0909,\n",
      "          0.0198, -0.0539, -0.0909, -0.1817, -0.0129,  0.1212, -0.0867,  0.0922,\n",
      "          0.1473, -0.0116,  0.1796, -0.0422,  0.1564,  0.0193],\n",
      "        [-0.0159, -0.0538, -0.1390, -0.1021, -0.0839,  0.0187,  0.0695, -0.1603,\n",
      "         -0.1332,  0.0341, -0.0385,  0.0124, -0.1707, -0.0274,  0.0605,  0.0035,\n",
      "         -0.0360, -0.1313,  0.0185, -0.1380, -0.1643,  0.0339,  0.0353, -0.0259,\n",
      "          0.0424,  0.0746, -0.1444, -0.0302, -0.0740,  0.1588],\n",
      "        [ 0.0362, -0.1479,  0.1222,  0.1438, -0.1750,  0.1249, -0.0841,  0.1443,\n",
      "         -0.1637, -0.0994,  0.0865,  0.1673, -0.0658, -0.1481,  0.1058,  0.1562,\n",
      "          0.1794, -0.1622,  0.1251,  0.1185,  0.0659,  0.0939, -0.0198,  0.1789,\n",
      "         -0.1231, -0.0165, -0.0634, -0.1029, -0.0498,  0.0470],\n",
      "        [ 0.1202,  0.0474,  0.0755, -0.1606,  0.0816, -0.0956,  0.1804, -0.0867,\n",
      "          0.0573,  0.0779, -0.1738,  0.0499, -0.0821, -0.0479,  0.1762, -0.1599,\n",
      "         -0.1662,  0.0476,  0.0424,  0.0729,  0.0334,  0.0447,  0.0979, -0.0242,\n",
      "          0.0363,  0.0847, -0.1319,  0.0650,  0.0478,  0.1391],\n",
      "        [ 0.1114, -0.0912, -0.0399, -0.0278,  0.1798,  0.1267, -0.1301, -0.0913,\n",
      "          0.0788, -0.0216,  0.0379,  0.1272, -0.1004,  0.0507, -0.0068,  0.1169,\n",
      "          0.1710, -0.1582, -0.1231,  0.1101, -0.0753, -0.0770,  0.0562, -0.0330,\n",
      "         -0.0333, -0.1622,  0.0437, -0.0541, -0.1307,  0.1810],\n",
      "        [-0.0209,  0.0251, -0.0965,  0.1576,  0.0357, -0.1772,  0.0798,  0.0991,\n",
      "         -0.1479, -0.1285, -0.1212,  0.1546, -0.1190, -0.1389,  0.1073, -0.0484,\n",
      "         -0.0334, -0.1533,  0.0175, -0.0408,  0.0649,  0.1566,  0.1569,  0.1818,\n",
      "         -0.1221, -0.0266, -0.0039,  0.1717, -0.0665,  0.0264],\n",
      "        [-0.0997,  0.1248,  0.1381, -0.1439, -0.1520, -0.0661,  0.1040, -0.0430,\n",
      "          0.1685, -0.1072,  0.0018,  0.1179, -0.0938,  0.0766, -0.1803, -0.1187,\n",
      "         -0.0889, -0.0325, -0.0710, -0.1549,  0.0069,  0.0864,  0.0995, -0.0952,\n",
      "          0.1023, -0.0153,  0.0554,  0.1549,  0.0202,  0.1819],\n",
      "        [-0.1495,  0.0607,  0.1142,  0.0594,  0.0716,  0.0975, -0.0661, -0.1065,\n",
      "          0.0941,  0.0764, -0.0045,  0.0100,  0.0620,  0.1415, -0.1616,  0.0506,\n",
      "          0.0588, -0.0224,  0.0215,  0.0552, -0.0393, -0.0655,  0.0734, -0.0129,\n",
      "          0.1173,  0.0653,  0.1487, -0.1297,  0.0594, -0.1339]],\n",
      "       requires_grad=True)), ('h1.bias', Parameter containing:\n",
      "tensor([-0.0454,  0.0714,  0.1263,  0.1359, -0.1747, -0.1277,  0.0646,  0.1044,\n",
      "        -0.1759,  0.1457,  0.1602, -0.1334, -0.0037,  0.1023, -0.0432,  0.1755,\n",
      "         0.0415,  0.1663,  0.1148,  0.1089], requires_grad=True)), ('h2.weight', Parameter containing:\n",
      "tensor([[-0.0682, -0.0430, -0.1060,  0.1286, -0.1453, -0.3360, -0.0165,  0.2786],\n",
      "        [-0.2310,  0.2101,  0.2293, -0.0786,  0.0678, -0.2894, -0.3287, -0.2132],\n",
      "        [-0.0506,  0.2347, -0.3390, -0.2252, -0.3034, -0.2125, -0.2265,  0.0541],\n",
      "        [-0.3274, -0.1425, -0.0159, -0.1192,  0.1651,  0.1282,  0.1159, -0.1002],\n",
      "        [ 0.1626, -0.0251,  0.3108,  0.2219,  0.2231,  0.2974, -0.0300, -0.1565]],\n",
      "       requires_grad=True)), ('h2.bias', Parameter containing:\n",
      "tensor([ 0.3335,  0.2898, -0.0882,  0.2165,  0.2703], requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(s1.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40363e20-64a8-4df8-9071-ce4dc0039dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
